{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import List, Callable\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA DOWNLOADING AND PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Meta data from yfinance\n",
    "GetFacebookInformation = yf.Ticker(\"META\") # Create a ticker\n",
    "pd.DataFrame(GetFacebookInformation.info).head() # Retrieve general information about the Meta stock\n",
    "GetFacebookInformation.history(period='5y').info() # Retrieve historical stock data for Meta for the past 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us get historical stock prices for Facebook \n",
    "data =  GetFacebookInformation.history(period=\"5y\")\n",
    "# selecting independent feature's data\n",
    "vectors = data[['Open', 'Close', 'High', 'Low']].values.tolist() # Converts data to a list\n",
    "vectors.pop() # Remove the last element\n",
    "for vector in vectors: # Add an intercept term (bias) of 1 to each vector\n",
    "    vector.append(1)\n",
    "# vectors now that column that correspond to intercept \n",
    "vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting dependent feature's data\n",
    "y_vectors = data[['Open', 'Close', 'High', 'Low']].values.tolist() # Converts data to a list\n",
    "y_values = [sum(y_vector) / 4 for y_vector in y_vectors] # Calculate average values for each row\n",
    "y_values.pop(0) # Remove the last element\n",
    "len(y_values) # Check the length of y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "split_index = int(0.8 * len(vectors)) # 80% of data for training, 20% for testing\n",
    "train_vectors, test_vectors = vectors[:split_index], vectors[split_index:] # Train value contain 80% of vectors and y_values, test is the 20% remaining\n",
    "train_y_values, test_y_values = y_values[:split_index], y_values[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC FUNCTIONS FOR ALGEBRA CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List # define vector\n",
    "Vector = List[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #define scalar product\n",
    "def dot(v, w) -> float:\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model's prediction function\n",
    "def predict(x: Vector, beta: Vector) -> float: \n",
    "    return dot(x,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the element-wise sum for a list of vectors\n",
    "# i.e: new_vector[i] = sum of all vector[i] for vector in vectors\n",
    "def vector_sum(vectors: List[Vector]) -> Vector:    \n",
    "    assert vectors, \"No vectors provided!\" # Ensures that vectors is not empty\n",
    "    num_elements = len(vectors[0]) # Number of elements in each vector\n",
    "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\" # Checks that all vectors in vectors have the same length\n",
    "    return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new list\n",
    "def scalar_multiply(c: float, v:Vector) ->Vector: \n",
    "    return [c *v_i for v_i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the element-wise mean for a list of vectors\n",
    "def vector_mean(vectors: List[Vector]) -> Vector: \n",
    "    n = len(vectors)\n",
    "    return scalar_multiply(1/n, vector_sum(vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION FOR CALCULATING GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error calculating function\n",
    "def error(x: Vector, y:float, beta: Vector) ->float: \n",
    "    return predict(x,beta) -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square of error calculating function\n",
    "def squared_error(x:Vector, y: float, beta: Vector) -> float: \n",
    "    return error(x,y,beta) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of each x vector in SSE function\n",
    "def sqerror_gradient(x: Vector, y: float, beta:Vector) -> Vector:\n",
    "    err = error(x,y,beta)\n",
    "    return [2*err*x_i for x_i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALCULATING GRADIENT STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a new vector that has move in the negative gradient direction by a 'step_size' amount\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
    "    return [v_i - step_size * gradient_i for v_i, gradient_i in zip(v, gradient)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a optimize weight vector correspond to features\n",
    "def least_squares_fit(xs: List[Vector], ys: List[float], learning_rate: float = 0.00000001, num_steps: int = 10000, batch_size: int = 1) -> Vector:\n",
    "    guess = [0.0] * len(xs[0]) # Initialize the initial guess for coefficients\n",
    "    for _ in range(num_steps):\n",
    "        for start in range(0, len(xs), batch_size):\n",
    "            batch_xs = xs[start:start + batch_size] # Select a batch of input vectors\n",
    "            batch_ys = ys[start:start + batch_size] # Select corresponding batch of output values\n",
    "            gradient = vector_mean([sqerror_gradient(x, y, guess) for x, y in zip(batch_xs, batch_ys)]) # Computes the mean gradient\n",
    "            guess = gradient_step(guess, gradient, learning_rate) # Update the coefficients\n",
    "    return guess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00000001\n",
    "beta = least_squares_fit(train_vectors, train_y_values, learning_rate, 30000, 1)\n",
    "print(\"Nghiệm tìm được bằng least_squares_fit:\", beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression() # Create a LinearRegression model instance\n",
    "new_vectors = train_vectors \n",
    "for vector in new_vectors:\n",
    "    vector.pop() # Remove the last element\n",
    "model.fit(new_vectors, train_y_values) # Fit the model\n",
    "coef = model.coef_.tolist() # Coefficients converted to list\n",
    "coef.append(model.intercept_) # Append the intercept to coefficients list\n",
    "print(\"Hệ số của các biến:\", coef)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đây là sử dụng model của sklearn để predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[['Open', 'Close', 'High', 'Low']].values.tolist() # convert to list\n",
    "last_day_data = test[-1] # Select the last day's data\n",
    "last_day_data.append(1) # Append the intercept term\n",
    "y = predict(last_day_data, beta) # Predict the stock price\n",
    "print(\"Giá cổ phiếu dự đoán ngày tiếp theo (bằng least square fit): \", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions using custom least squares fit\n",
    "train_predictions_custom = [predict(x, beta) for x in train_vectors]\n",
    "test_predictions_custom = [predict(x, beta) for x in test_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict with sklearn's LinearRegression\n",
    "model = LinearRegression() # create a model\n",
    "model.fit(train_vectors, train_y_values) # Fit the model\n",
    "for test in test_vectors:\n",
    "    test.pop() # Remove the last element\n",
    "train_predictions_sklearn = model.predict(new_vectors) # Predictions on training data\n",
    "test_predictions_sklearn = model.predict(test_vectors) # Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = data[['Open', 'Close', 'High', 'Low','Volume']].corr()\n",
    "fig, ax = plt.subplots(figsize=(10, 6)) # Set up the figure and axis for plotting\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".4f\", cmap='coolwarm', ax=ax, cbar=False, annot_kws={\"size\": 10}) # Create heatmap using seaborn\n",
    "\n",
    "# Set table config\n",
    "ax.set_title('Relationship between the independent parameters', fontsize=14)\n",
    "ax.set_xticklabels(corr_matrix.columns, rotation=0, fontsize=10) # Set label for x axis\n",
    "ax.set_yticklabels(corr_matrix.columns, rotation=0, fontsize=10) # Set label for y axis\n",
    "\n",
    "# Show table\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as png file\n",
    "fig.savefig('relationship_table.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating evaluation metrics\n",
    "def adjusted_r2(r2, n, p):\n",
    "    \"\"\" calculate the proportion of y values explain only by relevant independent variables\"\"\"\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Evalute metrics dictionary\n",
    "metrics = {\n",
    "    \"Model\": [],\n",
    "    \"R-Squared\": [],\n",
    "    \"Adjusted R-Squared\": [],\n",
    "    \"Multiple R\": [],\n",
    "    \"Standard Error\": [],\n",
    "    \"MSE\": []\n",
    "} \n",
    "\n",
    "# Evaluate model function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    r2 = r2_score(y_true, y_pred) # measures the proportion\n",
    "    adj_r2 = adjusted_r2(r2, len(y_true), len(train_vectors[0])) # calculated using the adjusted_r2\n",
    "    mse = mean_squared_error(y_true, y_pred) # measures the average squared difference between the predicted and actual values\n",
    "    std_error = np.sqrt(mse) # Standard error of the model predictions, calculated as the square root of MSE\n",
    "    metrics[\"Model\"].append(model_name)\n",
    "    metrics[\"R-Squared\"].append(r2)\n",
    "    metrics[\"Adjusted R-Squared\"].append(adj_r2)\n",
    "    metrics[\"Multiple R\"].append(np.sqrt(r2))\n",
    "    metrics[\"Standard Error\"].append(std_error)\n",
    "    metrics[\"MSE\"].append(mse)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(test_y_values, test_predictions_custom, \"Custom Least Squares\")\n",
    "evaluate_model(test_y_values, test_predictions_sklearn, \"Sklearn LinearRegression\")\n",
    "\n",
    "# Display evaluation metrics\n",
    "evaluation_df = pd.DataFrame(metrics)\n",
    "print(evaluation_df)\n",
    "\n",
    "# Save the model\n",
    "import pickle\n",
    "\n",
    "with open('linear_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "with open('custom_least_squares_model.pkl', 'wb') as file:\n",
    "    pickle.dump(beta, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ biểu đồ scatter plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Biểu đồ scatter plot cho tập train\n",
    "plt.subplot(1, 2, 1) # Creating a subplot\n",
    "plt.scatter(train_y_values, train_predictions_custom, label=\"Custom Model Predictions - Train\", alpha=1,color='blue') # Plot a scatter plot of custom model\n",
    "plt.scatter(train_y_values, train_predictions_sklearn, label=\"Sklearn Model Predictions - Train\", alpha=0.45,color='yellow') # Plot a scatter plot of Sklearn\n",
    "plt.plot([min(train_y_values), max(train_y_values)], [min(train_y_values), max(train_y_values)], color='black') # Plots a diagonal line\n",
    "plt.xlabel('Actual Prices - Train') # Sets the x-axis label\n",
    "plt.ylabel('Predicted Prices - Train') # Sets the x-axis label\n",
    "plt.title('Training Data') # Set the title\n",
    "plt.legend() # Displays a legend\n",
    "\n",
    "# Biểu đồ scatter plot cho tập test\n",
    "plt.subplot(1, 2, 2) # Creating a subplot\n",
    "plt.scatter(test_y_values, test_predictions_custom, label=\"Custom Model Predictions - Test\", alpha=1,color='blue') # Plot a scatter plot of custom model\n",
    "plt.scatter(test_y_values, test_predictions_sklearn, label=\"Sklearn Model Predictions - Test\", alpha=0.45, color='yellow') # Plot a scatter plot of Sklearn\n",
    "plt.plot([min(test_y_values), max(test_y_values)], [min(test_y_values), max(test_y_values)], color='black') # Plots a diagonal line\n",
    "plt.xlabel('Actual Prices - Test') # Sets the x-axis label\n",
    "plt.ylabel('Predicted Prices - Test') # Sets the x-axis label\n",
    "plt.title('Testing Data') # Set the title\n",
    "plt.legend() # Displays a legend\n",
    "plt.savefig('model evaluation.png',dpi=100, bbox_inches='tight') # Save the figure\n",
    "plt.show() # Display the plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
